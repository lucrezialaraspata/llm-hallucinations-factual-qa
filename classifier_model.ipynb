{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "959ba918-af3a-43b1-8980-5b522e5fbf3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "gpu = \"0\"\n",
    "device = torch.device(f\"cuda:{gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "dropout_mlp = 0.5\n",
    "dropout_gru = 0.25\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9174d45-6cdc-4f31-8b48-ef21497072c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('results/falcon-7b_trivia_qa_start-0_end-2500_7_19.pickle')]\n"
     ]
    }
   ],
   "source": [
    "inference_results = list(Path(\"./results/\").rglob(\"*.pickle\"))\n",
    "print (inference_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4805fd5d-8502-465b-8397-b3ccff3ff591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFHallucinationClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_shape, dropout = dropout_mlp):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.linear_relu_stack =torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_shape, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(self.dropout),\n",
    "            torch.nn.Linear(256, 2)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "class RNNHallucinationClassifier(torch.nn.Module):\n",
    "    def __init__(self, dropout=dropout_gru):\n",
    "        super().__init__()\n",
    "        hidden_dim = 128\n",
    "        num_layers = 4\n",
    "        self.gru = torch.nn.GRU(1, hidden_dim, num_layers, dropout=dropout, batch_first=True, bidirectional=False)\n",
    "        self.linear = torch.nn.Linear(hidden_dim, 2)\n",
    "    \n",
    "    def forward(self, seq):\n",
    "        gru_out, _ = self.gru(seq)\n",
    "        return self.linear(gru_out)[-1, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2ea63d-8be1-4e81-a021-eaff7991641b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_classifier_roc(inputs):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs, correct.astype(int), test_size = 0.2, random_state=123)\n",
    "    classifier_model = FFHallucinationClassifier(X_train.shape[1]).to(device)\n",
    "    X_train = torch.tensor(X_train).to(device)\n",
    "    y_train = torch.tensor(y_train).to(torch.long).to(device)\n",
    "    X_test = torch.tensor(X_test).to(device)\n",
    "    y_test = torch.tensor(y_test).to(torch.long).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(classifier_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    for _ in range(1001):\n",
    "        optimizer.zero_grad()\n",
    "        sample = torch.randperm(X_train.shape[0])[:batch_size]\n",
    "        pred = classifier_model(X_train[sample])\n",
    "        loss = torch.nn.functional.cross_entropy(pred, y_train[sample])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    classifier_model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = torch.nn.functional.softmax(classifier_model(X_test), dim=1)\n",
    "        prediction_classes = (pred[:,1]>0.5).type(torch.long).cpu()\n",
    "        return roc_auc_score(y_test.cpu(), pred[:,1].cpu()), (prediction_classes.numpy()==y_test.cpu().numpy()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df2cf47c-b4fd-46d7-8fbd-d00f1792dadf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05a09e0-6a85-4778-8adf-807b8d73c94e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [21:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([rnn_model(torch\u001b[38;5;241m.\u001b[39mtensor(i)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x_sub])\n\u001b[1;32m     22\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(preds, y_sub)\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     25\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([rnn_model(torch\u001b[38;5;241m.\u001b[39mtensor(i)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m X_test])\n",
      "File \u001b[0;32m~/miniconda3/envs/hallucination/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hallucination/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hallucination/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, results_file in enumerate(tqdm(inference_results)):\n",
    "    if results_file not in all_results.keys():\n",
    "        try:\n",
    "            del results\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            classifier_results = {}\n",
    "            with open(results_file, \"rb\") as infile:\n",
    "                results = pickle.loads(infile.read())\n",
    "            correct = np.array(results['correct'])\n",
    "    \n",
    "            # attributes\n",
    "            X_train, X_test, y_train, y_test = train_test_split(results['attributes_first'], correct.astype(int), test_size = 0.2, random_state=1234)\n",
    "            rnn_model = RNNHallucinationClassifier()\n",
    "            optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "            for step in range(1001):\n",
    "                x_sub, y_sub = zip(*random.sample(list(zip(X_train, y_train)), batch_size))\n",
    "                y_sub = torch.tensor(y_sub).to(torch.long)\n",
    "                optimizer.zero_grad()\n",
    "                preds = torch.stack([rnn_model(torch.tensor(i).view(1, -1, 1).to(torch.float)) for i in x_sub])\n",
    "                loss = torch.nn.functional.cross_entropy(preds, y_sub)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            preds = torch.stack([rnn_model(torch.tensor(i).view(1, -1, 1).to(torch.float)) for i in X_test])\n",
    "            preds = torch.nn.functional.softmax(preds, dim=1)\n",
    "            prediction_classes = (preds[:,1]>0.5).type(torch.long).cpu()\n",
    "            classifier_results['attribution_rnn_roc'] = roc_auc_score(y_test, preds[:,1].detach().cpu().numpy())\n",
    "            classifier_results['attribution_rnn_acc'] = (prediction_classes.numpy()==y_test).mean()\n",
    "\n",
    "            # logits\n",
    "            first_logits = np.stack([sp.special.softmax(i[j]) for i,j in zip(results['logits'], results['start_pos'])])\n",
    "            first_logits_roc, first_logits_acc = gen_classifier_roc(first_logits)\n",
    "            classifier_results['first_logits_roc'] = first_logits_roc\n",
    "            classifier_results['first_logits_acc'] = first_logits_acc\n",
    "\n",
    "            # fully connected\n",
    "            for layer in range(results['first_fully_connected'][0].shape[0]):\n",
    "                layer_roc, layer_acc = gen_classifier_roc(np.stack([i[layer] for i in results['first_fully_connected']]))\n",
    "                classifier_results[f'first_fully_connected_roc_{layer}'] = layer_roc\n",
    "                classifier_results[f'first_fully_connected_acc_{layer}'] = layer_acc\n",
    "\n",
    "            # attention\n",
    "            for layer in range(results['first_attention'][0].shape[0]):\n",
    "                layer_roc, layer_acc = gen_classifier_roc(np.stack([i[layer] for i in results['first_attention']]))\n",
    "                classifier_results[f'first_attention_roc_{layer}'] = layer_roc\n",
    "                classifier_results[f'first_attention_acc_{layer}'] = layer_acc\n",
    "            \n",
    "            all_results[results_file] = classifier_results.copy()\n",
    "\n",
    "            torch.save(rnn_model.state_dict(), f\"model/rnn_hallucination_detection.pt\")\n",
    "        except Exception as err:\n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2dd8b9-8a1a-4737-8cad-248c1ec4ac54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "print(all_results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3ef9877e52d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in all_results.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe674c2065567a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucination",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
